{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T22:43:06.548637Z",
     "start_time": "2025-03-13T22:43:05.401188Z"
    }
   },
   "outputs": [],
   "source": [
    "pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T22:43:07.510640Z",
     "start_time": "2025-03-13T22:43:06.569091Z"
    }
   },
   "outputs": [],
   "source": [
    "pip install dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T22:43:24.783776Z",
     "start_time": "2025-03-13T22:43:07.535811Z"
    }
   },
   "outputs": [],
   "source": [
    "pip install git+https://github.com/DataDog/dd-trace-py.git@yahya/update-prompt-annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T22:43:24.798695Z",
     "start_time": "2025-03-13T22:43:24.788870Z"
    }
   },
   "outputs": [],
   "source": [
    "from ddtrace.llmobs import LLMObs\n",
    "from ddtrace.llmobs.utils import Prompt\n",
    "from ddtrace import patch\n",
    "from openai import OpenAI\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "patch(openai=True)\n",
    "\n",
    "openai.api_key = os.environ.get(\"openai_api_key\")\n",
    "client = OpenAI()\n",
    "load_dotenv()\n",
    "\n",
    "LLMObs.enable(\n",
    "    api_key=os.environ.get(\"dd_api_key\"),\n",
    "    site=os.environ.get(\"dd_site\"),\n",
    "    ml_app=\"prompt-tracking-sandbox-v3\",\n",
    "    service=\"prompt-tracking-sandbox-v3\",\n",
    "    agentless_enabled=True,\n",
    "    env=\"testing\",\n",
    "    integrations_enabled=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T22:43:24.842096Z",
     "start_time": "2025-03-13T22:43:24.839374Z"
    }
   },
   "outputs": [],
   "source": [
    "prompt_id = \"travel-rec-1\"\n",
    "prompt_name = \"testing_prompt\"\n",
    "\n",
    "def query_openai(system_prompt=None, user_prompt=None, variables=[], model=\"gpt-4-turbo\", max_tokens=100, temperature=0.7):\n",
    "     \"\"\" Sends a prompt to the OpenAI API and returns the text response. \"\"\" \n",
    "     if system_prompt and user_prompt:\n",
    "          system_prompt_rendered = system_prompt.format(**variables)\n",
    "          user_prompt_rendered = user_prompt.format(**variables)\n",
    "          completion = client.chat.completions.create(\n",
    "               model=model,\n",
    "               max_tokens=max_tokens,\n",
    "               temperature=temperature,\n",
    "               messages=[{\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": system_prompt_rendered\n",
    "                    },\n",
    "                    {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": user_prompt_rendered\n",
    "                    }]\n",
    "          )\n",
    "     elif user_prompt:\n",
    "          user_prompt_rendered = user_prompt.format(**variables)\n",
    "          completion = client.chat.completions.create(\n",
    "               model=model,\n",
    "               max_tokens=max_tokens,\n",
    "               temperature=temperature,\n",
    "               messages=[{\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": user_prompt_rendered\n",
    "                    }]\n",
    "          )\n",
    "     elif system_prompt:\n",
    "            system_prompt_rendered = system_prompt.format(**variables)\n",
    "            completion = client.chat.completions.create(\n",
    "                 model=model,\n",
    "                 max_tokens=max_tokens,\n",
    "                 temperature=temperature,\n",
    "                 messages=[{\n",
    "                        \"role\": \"system\",\n",
    "                        \"content\": system_prompt_rendered\n",
    "                        }]\n",
    "            )\n",
    "     return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to annotate a prompt to a span \n",
    "In order to trace the prompt we wrap the openai call with LLMObs.prompt_context or LLMObs.annotation_context.\n",
    "Example :\n",
    "\n",
    "\"\"\"\n",
    "with LLMObs.prompt_context(id=prompt_id, \n",
    "                           name=prompt_name, \n",
    "                           version=\"1.0.0\",\n",
    "                           template=[(\"User\", prompt_step1)], \n",
    "                           variables=variables_step1\n",
    "                           ):\n",
    "\"\"\"\n",
    "Or\n",
    "\"\"\"\n",
    "with LLMObs.annotation_context(prompt=Prompt(id=prompt_id,\n",
    "                           name=prompt_name,\n",
    "                           version=\"1.0.0\",\n",
    "                           template=[(\"User\", prompt_step1)],\n",
    "                           variables=variables_step1\n",
    "                           )):\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 simple user prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T22:43:52.600098Z",
     "start_time": "2025-03-13T22:43:24.943397Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== USER Prompt Template (Step 1) ===\n",
      "{user_prompt}\n",
      "\n",
      "=== Variables (Step 1) ===\n",
      "{'user_prompt': 'Suggest a destination and a restaurant.'}\n",
      "\n",
      "=== Response (Step 1) ===\n",
      "**Destination: Kyoto, Japan**\n",
      "\n",
      "Kyoto, the cultural heart of Japan, is renowned for its classical Buddhist temples, as well as gardens, imperial palaces, Shinto shrines, and traditional wooden houses. It's also famous for formal traditions such as kaiseki dining, consisting of multiple courses of precise dishes, and geisha, female entertainers known for their skills in dance and music.\n",
      "\n",
      "**Restaurant: Nakamura**\n",
      "\n",
      "Nakamura is a Michelin-starred restaurant in Kyoto that\n"
     ]
    }
   ],
   "source": [
    "prompt_step1 = \"{user_prompt}\"\n",
    "variables_step1 = {\"user_prompt\": \"Suggest a destination and a restaurant.\"}\n",
    "\n",
    "with LLMObs.prompt_context(id=prompt_id, \n",
    "                           name=prompt_name, \n",
    "                           version=\"1.0.0\",\n",
    "                           template=[(\"User\", prompt_step1)], \n",
    "                           variables=variables_step1\n",
    "                           ):\n",
    "    response_step1 = query_openai(user_prompt=prompt_step1, variables=variables_step1)\n",
    "\n",
    "print(\"=== USER Prompt Template (Step 1) ===\") \n",
    "print(prompt_step1) \n",
    "print(\"\\n=== Variables (Step 1) ===\") \n",
    "print(variables_step1)\n",
    "print(\"\\n=== Response (Step 1) ===\") \n",
    "print(response_step1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2 add examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T22:44:10.961358Z",
     "start_time": "2025-03-13T22:43:52.615593Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== USER Prompt template (Step 2) ===\n",
      "\n",
      "    {user_prompt}\n",
      "    Examples:\n",
      "        {examples}\n",
      "\n",
      "\n",
      "=== Variables (Step 2) ===\n",
      "{'user_prompt': 'Suggest a destination and a restaurant.', 'examples': '\\nExample 1:\\nInput: \"Bob: Can you suggest a restaurant?\"\\nOutput: \"Based on your preferences for Italian cuisine, I recommend trying Luigi\\'s Trattoria.\"\\n\\nExample 2:\\nInput: \"Alice: What\\'s a good place for nature walks?\"\\nOutput: \"Considering your love for scenic views, I suggest visiting Green Park Gardens.\"\\n'}\n",
      "\n",
      "=== Response (Step 2) ===\n",
      "Input: \"Jake: What's a good city to explore historical sites?\"\n",
      "Output: \"Given your interest in history, I recommend visiting Rome. Be sure to dine at La Pergola for a fantastic culinary experience with a view of the city's ancient architecture.\"\n"
     ]
    }
   ],
   "source": [
    "prompt_step2 = \"\"\"\n",
    "    {user_prompt}\n",
    "    Examples:\n",
    "        {examples}\n",
    "\"\"\"\n",
    "\n",
    "# Examples\n",
    "examples_step2 = \"\"\"\n",
    "Example 1:\n",
    "Input: \"Bob: Can you suggest a restaurant?\"\n",
    "Output: \"Based on your preferences for Italian cuisine, I recommend trying Luigi's Trattoria.\"\n",
    "\n",
    "Example 2:\n",
    "Input: \"Alice: What's a good place for nature walks?\"\n",
    "Output: \"Considering your love for scenic views, I suggest visiting Green Park Gardens.\"\n",
    "\"\"\"\n",
    "\n",
    "variables_step2 = {\n",
    "    \"user_prompt\": \"Suggest a destination and a restaurant.\", \n",
    "    \"examples\": examples_step2\n",
    "    }\n",
    "\n",
    "with LLMObs.annotation_context(prompt=Prompt(id=prompt_id, \n",
    "                           name=prompt_name, \n",
    "                           version=\"1.1.0\",\n",
    "                           template=[(\"User\", prompt_step2)], \n",
    "                           variables=variables_step2\n",
    "                           )):\n",
    "    response_step2 = query_openai(user_prompt=prompt_step2, variables=variables_step2)\n",
    "\n",
    "print(\"=== USER Prompt template (Step 2) ===\") \n",
    "print(prompt_step2) \n",
    "print(\"\\n=== Variables (Step 2) ===\")\n",
    "print(variables_step2)\n",
    "print(\"\\n=== Response (Step 2) ===\") \n",
    "print(response_step2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3 add system prompt with constraints and examples and lighten the user prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T22:44:24.635603Z",
     "start_time": "2025-03-13T22:44:10.994277Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SYSTEM Prompt template (Step 3) ===\n",
      "\n",
      "            You are a recommendation bot with a focus on user preferences. Your main task is to provide the best recommendations based on provided user preferences.\n",
      "            Here are some rules and examples:\n",
      "\n",
      "            - Always base your responses on user preferences.\n",
      "            - Do not provide answers beyond the scope of the context given.\n",
      "\n",
      "            Example exchanges:\n",
      "            {examples}\n",
      "\n",
      "            Use these examples to format your responses. \n",
      "\n",
      "            {constraints}\n",
      "\n",
      "            Now, here's your specific task:\n",
      "    \n",
      "=== USER Prompt template (Step 3) ===\n",
      "{user_prompt}\n",
      "\n",
      "=== Variables (Step 3) ===\n",
      "{'user_prompt': 'Suggest a destination and a restaurant.', 'examples': '\\nExample 1:\\nInput: \"Bob: Can you suggest a restaurant?\"\\nOutput: \"Based on your preferences for Italian cuisine, I recommend trying Luigi\\'s Trattoria.\"\\n\\nExample 2:\\nInput: \"Alice: What\\'s a good place for nature walks?\"\\nOutput: \"Considering your love for scenic views, I suggest visiting Green Park Gardens.\"\\n', 'constraints': 'Do not ask the user for more information. Either provide a recommendation or state that data is insufficient for a recommendation.'}\n",
      "\n",
      "=== Response (Step 3) ===\n",
      "Since I don't have information about your preferences for travel destinations or types of cuisine, I'm unable to provide a specific recommendation.\n"
     ]
    }
   ],
   "source": [
    "system_prompt_step3 = \"\"\"\n",
    "            You are a recommendation bot with a focus on user preferences. Your main task is to provide the best recommendations based on provided user preferences.\n",
    "            Here are some rules and examples:\n",
    "\n",
    "            - Always base your responses on user preferences.\n",
    "            - Do not provide answers beyond the scope of the context given.\n",
    "\n",
    "            Example exchanges:\n",
    "            {examples}\n",
    "\n",
    "            Use these examples to format your responses. \n",
    "\n",
    "            {constraints}\n",
    "\n",
    "            Now, here's your specific task:\n",
    "    \"\"\"\n",
    "\n",
    "prompt_step3 = \"{user_prompt}\"\n",
    "\n",
    "examples_step3 = \"\"\"\n",
    "Example 1:\n",
    "Input: \"Bob: Can you suggest a restaurant?\"\n",
    "Output: \"Based on your preferences for Italian cuisine, I recommend trying Luigi's Trattoria.\"\n",
    "\n",
    "Example 2:\n",
    "Input: \"Alice: What's a good place for nature walks?\"\n",
    "Output: \"Considering your love for scenic views, I suggest visiting Green Park Gardens.\"\n",
    "\"\"\"\n",
    "\n",
    "variables_step3 = {\n",
    "    \"user_prompt\": \"Suggest a destination and a restaurant.\", \n",
    "    \"examples\": examples_step3, \n",
    "    \"constraints\": \"Do not ask the user for more information. Either provide a recommendation or state that data is insufficient for a recommendation.\"\n",
    "    }\n",
    "\n",
    "with LLMObs.annotation_context(prompt=Prompt(id=prompt_id, \n",
    "                           name=prompt_name, \n",
    "                           version=\"2.0.0\",\n",
    "                           template=[(\"System\",system_prompt_step3),(\"User\", prompt_step3)], \n",
    "                           variables=variables_step3\n",
    "                           )):\n",
    "    response_step3 = query_openai(system_prompt=system_prompt_step3, user_prompt=prompt_step3, variables=variables_step3)\n",
    "\n",
    "print(\"=== SYSTEM Prompt template (Step 3) ===\")\n",
    "print(system_prompt_step3)\n",
    "print(\"=== USER Prompt template (Step 3) ===\") \n",
    "print(prompt_step3)\n",
    "print(\"\\n=== Variables (Step 3) ===\")\n",
    "print(variables_step3)\n",
    "print(\"\\n=== Response (Step 3) ===\") \n",
    "print(response_step3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4 add context to system prompt and name of the user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T22:44:39.469249Z",
     "start_time": "2025-03-13T22:44:24.673780Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SYSTEM Prompt template (Step 4) ===\n",
      "\n",
      "        You are a recommendation bot with a focus on user preferences. Your main task is to provide the best recommendations based on provided user preferences.\n",
      "        Here are some rules and examples:\n",
      "\n",
      "        - Always base your responses on user preferences.\n",
      "        - Do not provide answers beyond the scope of the context given.\n",
      "\n",
      "        Example exchanges:\n",
      "        {examples}\n",
      "\n",
      "        Knowing the users' preferences is key to providing accurate recommendations. Here is the context for the current user:\n",
      "        {name}'s Context: {context}\n",
      "\n",
      "        Use these examples to format your responses. \n",
      "\n",
      "        {constraints}\n",
      "\n",
      "        Now, here's your specific task:\n",
      "    \n",
      "=== USER Prompt template (Step 4) ===\n",
      "{user_prompt}\n",
      "\n",
      "=== Variables (Step 4) ===\n",
      "{'name': 'Alice', 'context': 'Alice is allergic to peanuts and enjoys traveling to beaches and mountains. She prefers vegetarian food.', 'user_prompt': 'Suggest a destination and a restaurant.', 'examples': '\\nExample 1:\\nInput: \"Bob: Can you suggest a restaurant?\"\\nOutput: \"Based on your preferences for Italian cuisine, I recommend trying Luigi\\'s Trattoria.\"\\n\\nExample 2:\\nInput: \"Alice: What\\'s a good place for nature walks?\"\\nOutput: \"Considering your love for scenic views, I suggest visiting Green Park Gardens.\"\\n', 'constraints': 'Do not ask the user for more information. Either provide a recommendation or state that data is insufficient for a recommendation.'}\n",
      "\n",
      "=== Response (Step 4) ===\n",
      "Considering your preferences, I suggest visiting Maui, Hawaii for its beautiful beaches and scenic mountain views. For dining, you might want to try Moku Roots in Lahaina, which offers a creative vegetarian menu and is mindful about dietary restrictions like allergies.\n"
     ]
    }
   ],
   "source": [
    "system_prompt_step4 = \"\"\"\n",
    "        You are a recommendation bot with a focus on user preferences. Your main task is to provide the best recommendations based on provided user preferences.\n",
    "        Here are some rules and examples:\n",
    "\n",
    "        - Always base your responses on user preferences.\n",
    "        - Do not provide answers beyond the scope of the context given.\n",
    "\n",
    "        Example exchanges:\n",
    "        {examples}\n",
    "\n",
    "        Knowing the users' preferences is key to providing accurate recommendations. Here is the context for the current user:\n",
    "        {name}'s Context: {context}\n",
    "\n",
    "        Use these examples to format your responses. \n",
    "\n",
    "        {constraints}\n",
    "\n",
    "        Now, here's your specific task:\n",
    "    \"\"\"\n",
    "\n",
    "prompt_step4 = \"{user_prompt}\"\n",
    "\n",
    "examples_step4 = \"\"\"\n",
    "Example 1:\n",
    "Input: \"Bob: Can you suggest a restaurant?\"\n",
    "Output: \"Based on your preferences for Italian cuisine, I recommend trying Luigi's Trattoria.\"\n",
    "\n",
    "Example 2:\n",
    "Input: \"Alice: What's a good place for nature walks?\"\n",
    "Output: \"Considering your love for scenic views, I suggest visiting Green Park Gardens.\"\n",
    "\"\"\"\n",
    "\n",
    "variables_step4 = {\n",
    "    \"name\": \"Alice\",\n",
    "    \"context\": \"Alice is allergic to peanuts and enjoys traveling to beaches and mountains. She prefers vegetarian food.\",\n",
    "    \"user_prompt\": \"Suggest a destination and a restaurant.\", \n",
    "    \"examples\": examples_step4, \n",
    "    \"constraints\": \"Do not ask the user for more information. Either provide a recommendation or state that data is insufficient for a recommendation.\"\n",
    "    }\n",
    "\n",
    "with LLMObs.annotation_context(prompt=Prompt(id=prompt_id, \n",
    "                           name=prompt_name, \n",
    "                           version=\"2.1.0\",\n",
    "                           template=[(\"System\",system_prompt_step4),(\"User\", prompt_step4)], \n",
    "                           variables=variables_step4\n",
    "                           )):\n",
    "    response_step4 = query_openai(system_prompt=system_prompt_step4, user_prompt=prompt_step4, variables=variables_step4)\n",
    "\n",
    "print(\"=== SYSTEM Prompt template (Step 4) ===\")\n",
    "print(system_prompt_step4)\n",
    "print(\"=== USER Prompt template (Step 4) ===\") \n",
    "print(prompt_step4)\n",
    "print(\"\\n=== Variables (Step 4) ===\")\n",
    "print(variables_step4)\n",
    "print(\"\\n=== Response (Step 4) ===\") \n",
    "print(response_step4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T22:44:57.051763Z",
     "start_time": "2025-03-13T22:44:39.547759Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SYSTEM Prompt template (Step 5) ===\n",
      "\n",
      "    You are a recommendation bot with a focus on user preferences. Your main task is to provide the best recommendations based on provided user preferences while maintaining the given context. Here are the rules:\n",
      "    - Base recommendations primarily on user preferences.\n",
      "    - Respect and adhere strictly to the context boundaries; do not go beyond the provided scope.\n",
      "    - Personalization is key to every response.\n",
      "\n",
      "    Knowing the users' preferences is key to providing accurate recommendations. Here is the context for the current user:\n",
      "        {name}'s Context: {context}\n",
      "\n",
      "    Example exchanges: {examples}\n",
      "\n",
      "    Apply these examples to guide your response format, ensuring a focus on personal preferences within context. {constraints} \n",
      "    Now, here's your specific task:\n",
      "    \n",
      "=== USER Prompt template (Step 5) ===\n",
      "{user_prompt}\n",
      "\n",
      "=== Variables (Step 5) ===\n",
      "{'name': 'Alice', 'context': 'Alice is allergic to peanuts and enjoys traveling to beaches and mountains. She prefers vegetarian food.', 'user_prompt': 'Suggest a destination and a restaurant.', 'examples': '\\nExample 1:\\nInput: \"Bob: Can you suggest a restaurant?\"\\nOutput: \"Based on your preferences for Italian cuisine, I recommend trying Luigi\\'s Trattoria.\"\\n\\nExample 2:\\nInput: \"Alice: What\\'s a good place for nature walks?\"\\nOutput: \"Considering your love for scenic views, I suggest visiting Green Park Gardens.\"\\n', 'constraints': 'Do not ask the user for more information. Either provide a recommendation or state that data is insufficient for a recommendation.'}\n",
      "\n",
      "=== Response (Step 5) ===\n",
      "For a memorable trip, I recommend you visit Bali, Indonesia. It's famous for its stunning beaches and serene mountain landscapes, perfect for your love of nature. For dining, you can visit the Clear Café in Ubud, which offers a variety of vegetarian dishes in a beautiful, allergy-conscious setting. Enjoy your travels!\n"
     ]
    }
   ],
   "source": [
    "system_prompt_step5 = \"\"\"\n",
    "    You are a recommendation bot with a focus on user preferences. Your main task is to provide the best recommendations based on provided user preferences while maintaining the given context. Here are the rules:\n",
    "    - Base recommendations primarily on user preferences.\n",
    "    - Respect and adhere strictly to the context boundaries; do not go beyond the provided scope.\n",
    "    - Personalization is key to every response.\n",
    "\n",
    "    Knowing the users' preferences is key to providing accurate recommendations. Here is the context for the current user:\n",
    "        {name}'s Context: {context}\n",
    "\n",
    "    Example exchanges: {examples}\n",
    "\n",
    "    Apply these examples to guide your response format, ensuring a focus on personal preferences within context. {constraints} \n",
    "    Now, here's your specific task:\n",
    "    \"\"\"\n",
    "\n",
    "prompt_step5 = \"{user_prompt}\"\n",
    "\n",
    "examples_step5 = \"\"\"\n",
    "Example 1:\n",
    "Input: \"Bob: Can you suggest a restaurant?\"\n",
    "Output: \"Based on your preferences for Italian cuisine, I recommend trying Luigi's Trattoria.\"\n",
    "\n",
    "Example 2:\n",
    "Input: \"Alice: What's a good place for nature walks?\"\n",
    "Output: \"Considering your love for scenic views, I suggest visiting Green Park Gardens.\"\n",
    "\"\"\"\n",
    "\n",
    "variables_step5 = {\n",
    "    \"name\": \"Alice\",\n",
    "    \"context\": \"Alice is allergic to peanuts and enjoys traveling to beaches and mountains. She prefers vegetarian food.\",\n",
    "    \"user_prompt\": \"Suggest a destination and a restaurant.\", \n",
    "    \"examples\": examples_step5, \n",
    "    \"constraints\": \"Do not ask the user for more information. Either provide a recommendation or state that data is insufficient for a recommendation.\"\n",
    "    }\n",
    "\n",
    "with LLMObs.annotation_context(prompt=Prompt(id=prompt_id, \n",
    "                           name=prompt_name, \n",
    "                           version=\"2.2.0\",\n",
    "                           template=[(\"System\",system_prompt_step5),(\"User\", prompt_step5)], \n",
    "                           variables=variables_step5\n",
    "                           )):\n",
    "    response_step5 = query_openai(system_prompt=system_prompt_step5, user_prompt=prompt_step5, variables=variables_step5)\n",
    "\n",
    "print(\"=== SYSTEM Prompt template (Step 5) ===\")\n",
    "print(system_prompt_step5)\n",
    "print(\"=== USER Prompt template (Step 5) ===\") \n",
    "print(prompt_step5)\n",
    "print(\"\\n=== Variables (Step 5) ===\")\n",
    "print(variables_step5)\n",
    "print(\"\\n=== Response (Step 5) ===\") \n",
    "print(response_step5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T22:44:57.087485Z",
     "start_time": "2025-03-13T22:44:57.083791Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
